{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533faac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(tf.__version__)\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "DATA_FRACTION = 1\n",
    "MIN_AGREEMENT = 0\n",
    "\n",
    "resolution='69'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558114d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f8415",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('3class_map_a(p).csv')\n",
    "df = df.drop(df[df['agreement'] < MIN_AGREEMENT].index)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ed2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_E = df['gz2class'].str.startswith('E')\n",
    "num_E = mask_E.sum()\n",
    "print(\"Type E galaxies: \" + str(num_E))\n",
    "mask_S = df['gz2class'].str.match('^S[^B]')\n",
    "num_S = mask_S.sum()\n",
    "print(\"Type S galaxies: \" + str(num_S))\n",
    "mask_SB = df['gz2class'].str.startswith('SB')\n",
    "num_SB = mask_SB.sum()\n",
    "print(\"Type SB galaxies: \" + str(num_SB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_class = min(num_E, num_S, num_SB)    \n",
    "print(min_class)\n",
    "min_class = min_class * 1\n",
    "\n",
    "if num_E > min_class:\n",
    "    df_E = df[df[\"gz2class\"].str.startswith('E')].sample(n=min_class)\n",
    "else:\n",
    "    df_E = df[df[\"gz2class\"].str.startswith('E')]\n",
    "\n",
    "if num_S > min_class:\n",
    "    df_S = df[df[\"gz2class\"].str.match('^S[^B]')].sample(n=min_class)\n",
    "else:\n",
    "    df_S = df[df[\"gz2class\"].str.match('^S[^B]')]\n",
    "    \n",
    "if num_SB > min_class:\n",
    "    df_SB = df[df[\"gz2class\"].str.startswith('SB')].sample(n=min_class)\n",
    "else:\n",
    "    df_SB = df[df[\"gz2class\"].str.startswith('SB')]\n",
    "    \n",
    "df = pd.concat([df_E, df_S, df_SB])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c892445",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_E = df['gz2class'].str.startswith('E')\n",
    "num_E = mask_E.sum()\n",
    "print(\"Type E galaxies: \" + str(num_E))\n",
    "mask_S = df['gz2class'].str.match('^S[^B]')\n",
    "num_S = mask_S.sum()\n",
    "print(\"Type S galaxies: \" + str(num_S))\n",
    "mask_SB = df['gz2class'].str.startswith('SB')\n",
    "num_SB = mask_SB.sum()\n",
    "print(\"Type SB galaxies: \" + str(num_SB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set:\")\n",
    "print(\"-------------------------\")\n",
    "\n",
    "folder_path_E = \"images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03/images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03_train/E\"\n",
    "files_names_E = os.listdir(folder_path_E)\n",
    "\n",
    "folder_path_S = \"images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03/images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03_train/S\"\n",
    "files_names_S = os.listdir(folder_path_S)\n",
    "\n",
    "folder_path_SB = \"images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03/images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03_train/SB\"\n",
    "files_names_SB = os.listdir(folder_path_SB)\n",
    "\n",
    "photos_train_E = []\n",
    "for asset_id in df['asset_id']:\n",
    "    picture_path = os.path.join(folder_path_E, str(asset_id) + '.jpg')\n",
    "    if os.path.exists(picture_path):\n",
    "        picture = PILImage.open(picture_path)\n",
    "        picture = picture.convert(\"L\")\n",
    "        picture_array = np.array(picture)\n",
    "        photos_train_E.append((str(asset_id), picture_array))\n",
    "\n",
    "photos_train_S = []\n",
    "for asset_id in df['asset_id']:\n",
    "    picture_path = os.path.join(folder_path_S, str(asset_id) + '.jpg')\n",
    "    if os.path.exists(picture_path):\n",
    "        picture = PILImage.open(picture_path)\n",
    "        picture = picture.convert(\"L\")\n",
    "        picture_array = np.array(picture)\n",
    "        photos_train_S.append((str(asset_id), picture_array))\n",
    "\n",
    "photos_train_SB = []\n",
    "for asset_id in df['asset_id']:\n",
    "    picture_path = os.path.join(folder_path_SB, str(asset_id) + '.jpg')\n",
    "    if os.path.exists(picture_path):\n",
    "        picture = PILImage.open(picture_path)\n",
    "        picture = picture.convert(\"L\")\n",
    "        picture_array = np.array(picture)\n",
    "        photos_train_SB.append((str(asset_id), picture_array))\n",
    "        \n",
    "random.shuffle(photos_train_E)\n",
    "random.shuffle(photos_train_S)\n",
    "random.shuffle(photos_train_SB)\n",
    "\n",
    "photos_train_E = photos_train_E[:int(len(photos_train_E) / DATA_FRACTION)]\n",
    "photos_train_S = photos_train_S[:int(len(photos_train_S) / DATA_FRACTION)]\n",
    "photos_train_SB = photos_train_SB[:int(len(photos_train_SB) / DATA_FRACTION)]\n",
    "\n",
    "print(\"Elliptical galaxies: \" + str(len(photos_train_E)))\n",
    "print(\"Spiral galaxies: \" + str(len(photos_train_S)))\n",
    "print(\"Barred Spiral galaxies: \" + str(len(photos_train_SB)))\n",
    "\n",
    "photos_train = photos_train_E + photos_train_S + photos_train_SB\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Total galaxies: \" + str(len(photos_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c93732",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set:\")\n",
    "print(\"-------------------------\")\n",
    "\n",
    "folder_path_E = \"images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03/images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03_test/E\"\n",
    "files_names_E = os.listdir(folder_path_E)\n",
    "\n",
    "folder_path_S = \"images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03/images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03_test/S\"\n",
    "files_names_S = os.listdir(folder_path_S)\n",
    "\n",
    "folder_path_SB = \"images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03/images_E_S_SB_\"+resolution+\"x\"+resolution+\"_a_03_test/SB\"\n",
    "files_names_SB = os.listdir(folder_path_SB)\n",
    "\n",
    "photos_test_E = []\n",
    "for asset_id in df['asset_id']:\n",
    "    picture_path = os.path.join(folder_path_E, str(asset_id) + '.jpg')\n",
    "    if os.path.exists(picture_path):\n",
    "        picture = PILImage.open(picture_path)\n",
    "        picture = picture.convert(\"L\")\n",
    "        picture_array = np.array(picture)\n",
    "        photos_test_E.append((str(asset_id), picture_array))\n",
    "\n",
    "photos_test_S = []\n",
    "for asset_id in df['asset_id']:\n",
    "    picture_path = os.path.join(folder_path_S, str(asset_id) + '.jpg')\n",
    "    if os.path.exists(picture_path):\n",
    "        picture = PILImage.open(picture_path)\n",
    "        picture = picture.convert(\"L\")\n",
    "        picture_array = np.array(picture)\n",
    "        photos_test_S.append((str(asset_id), picture_array))\n",
    "\n",
    "photos_test_SB = []\n",
    "for asset_id in df['asset_id']:\n",
    "    picture_path = os.path.join(folder_path_SB, str(asset_id) + '.jpg')\n",
    "    if os.path.exists(picture_path):\n",
    "        picture = PILImage.open(picture_path)\n",
    "        picture = picture.convert(\"L\")\n",
    "        picture_array = np.array(picture)\n",
    "        photos_test_SB.append((str(asset_id), picture_array))\n",
    "\n",
    "random.shuffle(photos_test_E)\n",
    "random.shuffle(photos_test_S)\n",
    "random.shuffle(photos_test_SB)\n",
    "photos_test_E = photos_test_E[:int(len(photos_test_E) / DATA_FRACTION)]\n",
    "photos_test_S = photos_test_S[:int(len(photos_test_S) / DATA_FRACTION)]\n",
    "photos_test_SB = photos_test_SB[:int(len(photos_test_SB) / DATA_FRACTION)]\n",
    "\n",
    "print(\"Elliptical galaxies: \" + str(len(photos_test_E)))\n",
    "print(\"Spiral galaxies: \" + str(len(photos_test_S)))\n",
    "print(\"Barred Spiral galaxies: \" + str(len(photos_test_SB)))\n",
    "\n",
    "photos_test = photos_test_E + photos_test_S + photos_test_SB\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Total galaxies: \" + str(len(photos_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3dc841",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(photos_train)\n",
    "for i,tupla in enumerate(photos_train[:4]):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(tupla[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d2ee4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(photos_train, columns=['name','photo'])\n",
    "df_train['test'] = 0\n",
    "display(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737a133",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(photos_test, columns=['name','photo'])\n",
    "df_test['test'] = 1\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb2d49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df_concat['name'] = df_concat['name'].astype(int)\n",
    "df = df.merge(df_concat, left_on='asset_id', right_on='name',how='inner')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ea3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['test'] == 0:\n",
    "        X_train.append(row['photo'])\n",
    "        y_train.append(row['gz2class'])\n",
    "    else:\n",
    "        X_test.append(row['photo'])\n",
    "        y_test.append(row['gz2class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898196ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aaa3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(y_train))\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f60388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_test))\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4f902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(y_test))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329c791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).astype(float) / 255\n",
    "X_test = np.array(X_test).astype(float) / 255\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_element(element):\n",
    "    if element.startswith('SB'):\n",
    "        return 2\n",
    "    elif element.startswith('S'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3cccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = [convert_element(element) for element in y_train]\n",
    "y_test = [convert_element(element) for element in y_test]\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1484a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff7e1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0,\n",
    "    zoom_range=[0.8,1.2],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "\n",
    "iterator = datagen.flow(X_train, y_train, batch_size=25)\n",
    "\n",
    "X_batch, y_batch = iterator.next()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(X_batch[i].reshape(int(resolution),int(resolution)), cmap='gray')\n",
    "    plt.title('Label: {}'.format(y_batch[i]))\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "    Label 0 --> E\n",
    "    Label 1 --> S\n",
    "    Label 2 --> SB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61378b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_LEARNING_RATE = 0.001\n",
    "KFOLD_NSPLITS = 5\n",
    "\n",
    "BEST_MODEL_PATH = 'best_model_min_agreement_'+str(int(MIN_AGREEMENT*100))+'.h5'\n",
    "\n",
    "kf = KFold(n_splits=KFOLD_NSPLITS, shuffle=True)\n",
    "\n",
    "results = []\n",
    "results_E = []\n",
    "results_S = []\n",
    "results_SB = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):    \n",
    "    X_train_kf, X_test_kf = X_train[train_index], X_train[test_index]\n",
    "    y_train_kf, y_test_kf = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', input_shape=(int(resolution), int(resolution), 1)),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=15, min_lr=0.00001, verbose=1)\n",
    "    checkpoint = ModelCheckpoint(BEST_MODEL_PATH, monitor='val_sparse_categorical_accuracy', \n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    model.fit(datagen.flow(X_train_kf, y_train_kf, batch_size=BATCH_SIZE),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_test_kf,y_test_kf),\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "    \n",
    "    scores = model.evaluate(X_test_kf, y_test_kf)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
    "    \n",
    "    indexs = (y_test_kf == 0)\n",
    "    y_test_kf_E = y_test_kf[indexs]\n",
    "    X_test_kf_E = X_test_kf[indexs]\n",
    "    scores_E = model.evaluate(X_test_kf_E, y_test_kf_E)\n",
    "    print(\"Accuracy E: %.2f%%\" % (scores_E[1] * 100))\n",
    "    \n",
    "    indexs = (y_test_kf == 1)\n",
    "    y_test_kf_S = y_test_kf[indexs]\n",
    "    X_test_kf_S = X_test_kf[indexs]\n",
    "    scores_S = model.evaluate(X_test_kf_S, y_test_kf_S)\n",
    "    print(\"Accuracy S: %.2f%%\" % (scores_S[1] * 100))\n",
    "    \n",
    "    indexs = (y_test_kf == 2)\n",
    "    y_test_kf_SB = y_test_kf[indexs]\n",
    "    X_test_kf_SB = X_test_kf[indexs]\n",
    "    scores_SB = model.evaluate(X_test_kf_SB, y_test_kf_SB)\n",
    "    print(\"Accuracy SB: %.2f%%\" % (scores_SB[1] * 100))\n",
    "\n",
    "    results.append(scores[1] * 100)\n",
    "    results_E.append(scores_E[1] * 100)\n",
    "    results_S.append(scores_S[1] * 100)\n",
    "    results_SB.append(scores_SB[1] * 100)\n",
    "\n",
    "mean = np.mean(results)\n",
    "std = np.std(results)\n",
    "mean_E = np.mean(results_E)\n",
    "std_E = np.std(results_E)\n",
    "mean_S = np.mean(results_S)\n",
    "std_S = np.std(results_S)\n",
    "mean_SB = np.mean(results_SB)\n",
    "std_SB = np.std(results_SB)\n",
    "\n",
    "print('\\n')\n",
    "print(\"-----------------------------\")\n",
    "print(f\"Mean precision: {mean:.2f}\")\n",
    "print(f\"Standard deviation: {std:.2f}\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"Mean precision for E class: {mean_E:.2f}\")\n",
    "print(f\"Standard deviation for E class: {std_E:.2f}\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"Mean precision for S class: {mean_S:.2f}\")\n",
    "print(f\"Standard deviation for S class: {std_S:.2f}\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"Mean precision for SB class: {mean_SB:.2f}\")\n",
    "print(f\"Standard deviation for SB class: {std_SB:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799331c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(BEST_MODEL_PATH)\n",
    "\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "report = classification_report(y_test, y_pred, zero_division=1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94a164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = best_model.evaluate(X_test,y_test)\n",
    "print(\"General \\n%s: %.2f%%\" % (best_model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = (y_test == 0)\n",
    "y_test_E = y_test[indexs]\n",
    "X_test_E = X_test[indexs]\n",
    "scores_E = best_model.evaluate(X_test_E,y_test_E)\n",
    "print(\"Type E galaxy \\n%s: %.2f%%\" % (best_model.metrics_names[1], scores_E[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c816001",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = (y_test == 1)\n",
    "y_test_S = y_test[indexs]\n",
    "X_test_S = X_test[indexs]\n",
    "scores_S = best_model.evaluate(X_test_S,y_test_S)\n",
    "print(\"Type S galaxy \\n%s: %.2f%%\" % (best_model.metrics_names[1], scores_S[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f77e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = (y_test == 2)\n",
    "y_test_SB = y_test[indexs]\n",
    "X_test_SB = X_test[indexs]\n",
    "scores_SB = best_model.evaluate(X_test_SB,y_test_SB)\n",
    "print(\"Type SB galaxy \\n%s: %.2f%%\" % (best_model.metrics_names[1], scores_SB[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd06599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
